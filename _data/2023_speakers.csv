id,name,title,abstract,title-es,abstract-es,img,github,twitter,slides_url,talk_url
awilliams,Adrienne Williams,Data Is Power: How Unpaid labor & Stolen Data Train Amazon’s Technology & How Workers Can Take Their Power & Their Money Back.,"Amazon uses sensors in delivery vans and collects data through the Mentor app and company-issued scanners. Mentor is mandatory.  It monitors “risky” driving and distraction behind the wheel. Drivers are required to complete unpaid homework based on perceived “mistakes” determined by Mentor. Low scores means uninsurable drivers. Most drivers download the app onto personal phones instead of the company-provided scanners provided. To download the app onto one's personal phone means employees must allow Mentor to run in the background…always. In this talk, I will draw on my experience as a former Amazon delivery driver and organizer to discuss how tools implemented by Amazon to surveil its workers are, at the same time, used to collect workers' data and train future surveillance systems. This creates a vicious cycle that negatively affects workers. In my talk, I will describe how Amazon’s priorities shape the data that is collected, and how workers develop collective and individual strategies to trick the surveillance systems and regain control of the data that is collected from them.",Los datos son poder: cómo el trabajo no remunerado y los datos robados entrenan la tecnología de Amazon y cómo los trabajadores pueden recuperar su poder y su dinero.,"Amazon utiliza sensores en las furgonetas de reparto y recopila datos a través de la aplicación Mentor y de escáneres proporcionados por la empresa. Mentor es obligatorio. Controla la conducción ""de riesgo"" y las distracciones al volante. Los conductores deben hacer deberes no remunerados en función de los ""errores"" percibidos y determinados por Mentor. Las puntuaciones bajas significan conductores no asegurables. La mayoría de los conductores descargan la aplicación en sus teléfonos personales en lugar de hacerlo en los escáneres proporcionados por la empresa. Descargar la aplicación en el teléfono personal significa que los empleados deben permitir que Mentor se ejecute en segundo plano... siempre. En esta charla, me basaré en mi experiencia como antiguo conductor de reparto y organizador de Amazon para hablar de cómo las herramientas implementadas por Amazon para vigilar a sus trabajadores se utilizan, al mismo tiempo, para recopilar datos de los trabajadores y formar futuros sistemas de vigilancia. Esto crea un círculo vicioso que afecta negativamente a los trabajadores. En mi charla, describiré cómo las prioridades de Amazon determinan los datos que se recogen y cómo los trabajadores desarrollan estrategias colectivas e individuales para engañar a los sistemas de vigilancia y recuperar el control de los datos que se recogen de ellos.",https://www.dair-institute.org/about,,adrienneandgp,,
ahanna,Alex Hanna,Keynote,,Cambiando el marco: Los trabajos de ImageNet y los datos de IA,"Las tecnologías de inteligencia artificial (IA) como ChatGPT, Stable Diffusion y LaMDA han dado lugar a una industria multimillonaria de IA generativa y a una industria potencialmente mucho mayor de IA en general. Sin embargo, estas tecnologías no existirían si no fuera por la inmensa cantidad de datos que se extraen para hacerlas funcionar, la mano de obra de anotación mal pagada y explotada necesaria para el etiquetado y la moderación de contenidos, y los cuestionables acuerdos en torno al consentimiento para utilizar estos datos. Aunque los conjuntos de datos utilizados para entrenar y evaluar los modelos comerciales suelen quedar ocultos bajo el velo del secreto comercial, podemos aprender mucho sobre estos sistemas interrogando a determinados conjuntos de datos de acceso público que se consideran fundamentales en la investigación académica de la IA.

En esta charla, investigaré un único conjunto de datos, ImageNet. No es exagerado decir que sin ImageNet no tendríamos la actual ola de técnicas de aprendizaje profundo que impulsan casi todas las tecnologías modernas de IA. Comienzo desde tres puntos de vista: la historia de ImageNet desde la perspectiva de sus conservadores y su predecesor lingüístico WordNet, el testimonio de los anotadores de datos que etiquetaron millones de imágenes de ImageNet, y los sujetos de los datos y los creadores de las imágenes dentro de ImageNet. Desde el punto de vista académico, sitúo este análisis dentro de una teoría y una práctica más amplias de los estudios sobre infraestructuras. Desde el punto de vista práctico, apunto a una visión de la tecnología que no se base en prácticas de extracción de datos sin restricciones, explotación laboral y uso de imágenes sin el debido consentimiento.",,,,,
achowdhary,Anand Chowdhary,Running a Covid-19 nonprofit as a data maker,"In 2020, Anand Chowdhary and his team founded Karuna 2020, a nonprofit that distributed masks and food to migrant laborers and frontline workers in India. Using GitHub Actions, we developed several open-sourced workflows that automate tasks like generating open data APIs. For example, for every ration kit we distributed, we uploaded a face-blurred photo of the recipient and our REST API tells donors exactly where we're spending the money. All of this was built using Airtable, GitHub Actions, and CSV spreadsheets. In this talk, fellow data makers will learn about how we used automated processes for complete data transparency and the tooling we developed for running a nonprofit.",Dirigir una organización sin ánimo de lucro Covid-19 como creador de datos,"En 2020, Anand Chowdhary y su equipo fundaron Karuna 2020, una organización sin ánimo de lucro que distribuía máscaras y alimentos a trabajadores migrantes y de primera línea en la India. Gracias a GitHub Actions, desarrollamos varios flujos de trabajo de código abierto que automatizan tareas como la generación de API de datos abiertos. Por ejemplo, por cada kit de raciones que distribuimos, subimos una foto con la cara difuminada del receptor y nuestra API REST informa a los donantes exactamente de dónde gastamos el dinero. Todo esto se construyó utilizando Airtable, GitHub Actions y hojas de cálculo CSV. En esta charla, los creadores de datos aprenderán cómo utilizamos los procesos automatizados para una completa transparencia de los datos y las herramientas que desarrollamos para gestionar una organización sin ánimo de lucro.",https://anandchowdhary.com/anand.png,AnandChowdhary,AnandChowdhary,,
aanand,Apoorv Anand,A community driven initiative to crowdsource background details of 1700 High Court Judges in India,"India, the world's largest democracy, has a complex judicial system. The judgments delivered by courts touch upon almost every aspect of an individual's life. Despite playing a critical role, there is barely any data available on the background of judges in these courts. This information is crucial in building and sustaining public trust in the judicial process. It is also critical to inform about potential bias and conflicts of interest. The conceptualization of this dataset was a response to this information gap in India's judicial architecture.
We launched a campaign to build a public dataset titled Know Your High Court Judges (KHOJ) (https://justicehub.in/initiatives/khoj-india) to curate background information on judges. Over 15 months, we collected data on 43 variables on the judge's demographic, education, work experience, judicial appointments, transfers, etc. More than 30 students from law universities across the country, collaborated on crowd-sourcing data from court websites, and other publicly available documents on official websites.
In this talk, I would like to discuss: 
1. The story behind the conceptualization of this dataset
2 - The crucial roles played by members of the Justice Hub (https://justicehub.in/) community 
3 - The process of curating data and ensuring the accuracy of data points (collected by volunteers who had little to no background in working with data or technology) 
4 - Our learnings about how collaborative data curation processes can be used to collect data on other governance-related indicators that are not readily available and difficult to access through the Right to Information Act. 
5 - How this dataset has been contributing to building a discourse around transparency in judicial decision-making.",Una iniciativa comunitaria para recabar información sobre los antecedentes de 1.700 jueces de tribunales superiores de la India.,"India, la mayor democracia del mundo, tiene un complejo sistema judicial. Las sentencias dictadas por los tribunales afectan a casi todos los aspectos de la vida de una persona. A pesar de desempeñar un papel fundamental, apenas se dispone de datos sobre los antecedentes de los jueces de estos tribunales. Esta información es crucial para crear y mantener la confianza pública en el proceso judicial. También es fundamental para informar sobre posibles sesgos y conflictos de intereses. La conceptualización de este conjunto de datos fue una respuesta a esta laguna informativa en la arquitectura judicial de la India.
Lanzamos una campaña para crear un conjunto de datos públicos titulado Know Your High Court Judges (KHOJ) (https://justicehub.in/initiatives/khoj-india) para recopilar información sobre los jueces. A lo largo de 15 meses, recopilamos datos sobre 43 variables relativas a la demografía, la educación, la experiencia laboral, los nombramientos judiciales, los traslados, etc. de los jueces. Más de 30 estudiantes de universidades de Derecho de todo el país colaboraron en la recopilación de datos de sitios web de tribunales y otros documentos públicos disponibles en sitios web oficiales.
En esta charla, me gustaría discutir: 
1. La historia detrás de la conceptualización de este conjunto de datos
2 - El papel crucial desempeñado por los miembros de la comunidad Justice Hub (https://justicehub.in/) 
3 - El proceso de recopilación de datos y de garantía de la exactitud de los mismos (recopilados por voluntarios con poca o ninguna experiencia en el trabajo con datos o tecnología). 
4 - Lo que hemos aprendido sobre cómo los procesos colaborativos de recopilación de datos pueden utilizarse para recopilar datos sobre otros indicadores relacionados con la gobernanza que no están fácilmente disponibles y a los que es difícil acceder a través de la Ley de Derecho a la Información. 
5 - Cómo ha contribuido este conjunto de datos a crear un discurso en torno a la transparencia en la toma de decisiones judiciales.",https://civicdatalab.in/team/apoorv,https://github.com/apoorv74,,,
bgreshaketzovaras,Bastian Greshake Tzovaras,"Nothing about us, without us: Participatory approaches to make data by the people for the people","Data and AI have by now entered most – if not all – aspects of our lives, from the social over health to the workplace. With this datafication come myriad ethical questions: Which data should (and should not) be collected? What are acceptable uses for those data? And importantly, who gets to decide on these questions? More often than not, these questions are neither posed to nor answered by the people most affected by the data collection and might only be asked once harm has been done. Participatory approaches such as citizen science can be used to give those affected a voice by involving them right from the start and provides a pathway to improving data justice more broadly. This talk will give concrete examples to highlight how participation in fields such as transgender healthcare, Autism research and chronic diseases have been implemented and not only solved some of these issues, but also lead to better and more impactful research as a result. Furthermore, we will give a set of recommendations and ideas on how to start implementing such approaches in your own data practice.","Nada sobre nosotros, sin nosotros: Enfoques participativos para crear datos por el pueblo y para el pueblo","Los datos y la inteligencia artificial se han introducido ya en la mayoría -si no en todos- los aspectos de nuestras vidas, desde el ámbito social hasta el laboral, pasando por la sanidad. Con esta ""dataficación"" surgen innumerables cuestiones éticas: ¿Qué datos deben (y no deben) recopilarse? ¿Cuáles son los usos aceptables de esos datos? Y, lo que es aún más importante, ¿quién decide sobre estas cuestiones? En la mayoría de los casos, estas preguntas no se plantean a las personas más afectadas por la recopilación de datos ni son respondidas por ellas. Los enfoques participativos, como la ciencia ciudadana, pueden utilizarse para dar voz a los afectados, implicándolos desde el principio, y ofrecen así una vía para mejorar la justicia de los datos en general. En esta charla presentaremos ejemplos concretos que muestran cómo se ha aplicado la participación en campos como la atención sanitaria a transexuales, la investigación sobre el autismo y las enfermedades crónicas, y de esta manera no sólo se han resuelto algunos de estos problemas sino que también se ha conseguido como resultado una investigación mejor y más impactante. Además, daremos una serie de recomendaciones e ideas sobre cómo empezar a aplicar estos enfoques en su propia práctica de datos.",https://tzovar.as/assets/images/profile.jpg,gedankenstuecke,gedankenstuecke,,
cgreenwood,Cathi Greenwood,Speed Bumps on the Road to Innovating with Government Open Data ,"Along with improving transparency and efficiency, open government data is supposed to support entrepreneurship, in the form of user-friendly apps and other business innovations. But the reality often falls short of the ideal. Developers who want to use government data run into poor data quality and documentation, insufficient off-the-shelf data products, limited options for automation and other stumbling blocks. The Washington state (US) open government data team will highlight common development barriers and ways to overcome them, using examples from state agencies’ efforts to open data on transit, internet access, legal cannabis, licensing and more.",,,,,,,
dcarranza,Daniel Carranza,From garbage data to data on garbage,"Since 2013 on Data Uruguay we’ve been using open data to help people classify and correctly dispose recyclables. We centralise information on hundreds of initiatives in Uruguay and Colombia through DondeReciclo.uy and DondeReciclo.co, and we’re currently working on the national industrial waste tracking system with the ministry of the environment. We want to share the model and strategies we use to clean, standarise, visualise and publish data from dozens of private and públic stakeholders, through a project that has been fiantially sustainable for nine years.",De datos basura a datos sobre basura,"Desde 2013 en Data Uruguay usamos datos para ayudar a las personas a clasificar y disponer correctamente sus residuos. Centralizamos información de cientos de iniciativas en Uruguay y Colombia a través de DondeReciclo.uyy DondeReciclo.co, y estamos trabajando actualmente en el sistema nacional de trazabilidad de residuos industriales junto al Ministerio de Ambiente. Queremos compartir este modelo y las estrategias que usamos para limpiar, estandarizar, visualizar y publicar datos de docenas de actores públicos y privados, a través de un proyecto que ha logrado ser sostenible financieramente durante nueve años.",https://drive.google.com/file/d/1TCVsCVx9JG4S37pKcbVUc4Z6fM-vNWfR/view?usp=drivesdk,danielcarranza,danielcarranza,,
dbarnes,Darren Barnes,UK government: Building better data for a better future,How the UK's Office for National Statistics is leading a revolution across government organisations to bake CSV-W standard into the statistical production process by default. Our future is to pioneer an approach for delivering our statistics as linked open data for the web and build innovative and semantically correct data that can bring our data to life and tell stories that are accessible to everyone.,Gobierno británico: Mejores datos para un futuro mejor,La Oficina Nacional de Estadística del Reino Unido está liderando una revolución en las organizaciones gubernamentales para incorporar por defecto el estándar CSV-W al proceso de producción estadística. Nuestro futuro es ser pioneros en la entrega de nuestras estadísticas como datos abiertos enlazados para la web y construir datos innovadores y semánticamente correctos que puedan dar vida a nuestros datos y contar historias accesibles a todo el mundo.,,,,,
dmesquita,Deborah Mesquita,Identifying DDoS attacks on IoT devices using deep learning,"The ESP32 is a series of microcontrollers with integrated Wi-Fi. They offer an opportunity to empower a variety of IoT projects and users because they’re both low-cost and low-power. Security should be an essential part of the development of IoT systems, and these devices are easy targets for cyberattacks because of the poor cycles of update and maintenance. In this talk, we’ll see how we used deep learning and network traffic analysis knowledge to train and embed a model on the ESP32 capable of preventing DDoS attacks. IoT and machine learning combined can solve a lot of today’s problems (including problems of developing countries) and our main goal is to show with low-cost devices we can bring IoT project ideas to real life.",Identificación de ataques DoS en dispositivos IoT mediante aprendizaje profundo,"El ESP32 es una serie de microcontroladores con Wi-Fi integrado. Ofrecen la oportunidad de potenciar una variedad de proyectos de IoT porque son de bajo costo y bajo consumo. La seguridad debe ser una parte esencial del desarrollo de los sistemas IoT, y estos dispositivos son blancos fáciles de ataques cibernéticos debido a los ciclos deficientes de actualización y mantenimiento. En esta charla, veremos cómo usamos el aprendizaje profundo y el conocimiento del análisis del tráfico de red para entrenar e integrar un modelo en el ESP32 capaz de prevenir ataques DoS. IoT y el aprendizaje automático combinados pueden resolver muchos de los problemas actuales (incluidos los problemas de los países en desarrollo) y nuestro objetivo principal es demostrar que con dispositivos de bajo costo podemos llevar las ideas de proyectos de IoT a la vida real.",https://avatars.githubusercontent.com/u/2621484?v=4,https://github.com/dmesquita,,,
dbaker,Dylan Baker,Datasets Have Worldviews: Understanding Classification In Your Data,"The classification schemes that structure our datasets come with their own politics and histories. How do we uncover the values underpinning our data classification schemes, and what do we do when we find them? In this talk, we start by diving into the harmful real-world effects that different classification schemes can have. Then, we explore ways we can uncover the values hiding in our own data, and highlight different ways to mitigate harms perpetuated by the (always-imperfect) categorizations we make.",Los conjuntos de datos tienen visiones del mundo: Comprender la clasificación de sus datos,"Los esquemas de clasificación que estructuran nuestros conjuntos de datos vienen acompañados de sus propias políticas e historias. ¿Cómo descubrimos los valores que sustentan nuestros esquemas de clasificación de datos y qué hacemos cuando los encontramos? En esta charla, empezaremos por analizar los efectos nocivos que pueden tener los distintos sistemas de clasificación en el mundo real. A continuación, exploraremos las formas en que podemos descubrir los valores que se esconden en nuestros propios datos, y destacaremos diferentes maneras de mitigar los daños perpetuados por las categorizaciones (siempre imperfectas) que hacemos.",https://drive.google.com/file/d/1_A5VjjAih4RQEJd5dn68XjKKl5nwrJjQ/view?usp=share_link,,dylnbkr,,
,David Gonzalez y Mariel Fritz Patrick,How to find clues for your research in hundreds of datasets using Aleph,"Do you have your own databases that you would like to cross-reference with other datasets to see if company names and people are mentioned? Does your newsroom/organization work with a lot of PDFs and you need a tool that extracts the text so you can do keyword searches? Do you have a folder of documents that you want to work on securely with your colleagues?
Aleph can help you! This platform created by OCCRP helps journalists, activists and researchers to ""follow the money trail"". Its data organization model, called Follow the Money (FTM) allows to organize large databases in a secure environment to find connections between people and companies by cross-referencing entities in datasets. 
During the session we will show how to use the tool through concrete examples and real investigations. Our live demo will facilitate conversation and questions with the audience.",Cómo encontrar pistas para tus investigaciones en cientos de datasets usando Aleph,"Descripción: ¿Tienes bases de datos propias que te gustaría cruzar con otros datasets para ver si nombres de empresas y personas aparecen mencionados? ¿Tu redacción/organización trabaja con muchos PDF y necesitás una herramienta que extraiga el texto para poder hacer búsquedas de palabras clave? ¿Tienes una carpeta de documentos que quieres trabajar de manera segura con tus colegas?
¡Aleph puede ayudarte! Esta plataforma creada por OCCRP creada ayuda a periodistas, activistas e investigadores a ""seguir el rastro del dinero"". Su modelo de organización de datos, llamado Follow the Money (FTM) permite organizar grandes bases en un entorno seguro para encontrar conexiones entre personas y empresas a través del cruce de entidades en los datasets. 
Durante la sesión mostraremos cómo usar la herramienta a través de ejemplos concretos y de investigaciones reales. Nuestro demo en vivo, facilitará la conversación y preguntas con la audiencia.",https://www.occrp.org/en/aboutus/staff/eduardo-goulart,,deolhonosdados ,,
elkisa,Emma Laura Kisa,Opening up African Data,"A lot of data published by African governments and other institutions are stuck in pdf reports or websites. To solve this problem, Code for Africa built an open data portal called openAFRICA which is the continent's largest volunteer-driven portal. openAFRICA contains more than 6,000 African related datasets on various topics that are in a machine-readable format. openAFRICA promotes liberating data and the reuse and sharing of this open data.",Abrir los datos africanos,"Muchos de los datos publicados por los gobiernos y otras instituciones africanas están atrapados en informes en pdf o en sitios web. Para resolver este problema, Code for Africa creó un portal de datos abiertos llamado openAFRICA, que es el mayor portal del continente impulsado por voluntarios. openAFRICA contiene más de 6.000 conjuntos de datos relacionados con África sobre diversos temas en formato legible por máquina. openAFRICA promueve la liberación de datos y la reutilización y el intercambio de estos datos abiertos.",https://drive.google.com/file/d/1gWeLscUj5tYZNojoPcVxL45AJ5Gikjav/view?usp=sharing,,ELNamwanje,,
ekarev,Evgeny Karev,Frictionless Application (IDE for CSV),"This talk will present a new data management IDE for CSV and other formats that provides functionality to describe, extract, validate, and transform tabular data. It's a logical continuation of the Frictionless Data project's standards and software with a focus on the non-technical audience: data publishers, librarians, and, in general, people who prefer visual interfaces over command-line interfaces and programming languages.",Aplicación sin fricciones (IDE para CSV),"En esta charla se presentará un nuevo IDE de gestión de datos para CSV y otros formatos que ofrece funcionalidades para describir, extraer, validar y transformar datos tabulares. Se trata de una continuación lógica de las normas y el software del proyecto Frictionless Data centrada en el público no técnico: editores de datos, bibliotecarios y, en general, personas que prefieren las interfaces visuales a las interfaces de línea de comandos y los lenguajes de programación.",https://media-exp1.licdn.com/dms/image/C4D03AQEkDaXReUCMJg/profile-displayphoto-shrink_400_400/0/1589806579438?e=1673481600&v=beta&t=OwUxnWGUjHcoNsxVxMYi-jqXK5IEbYgV-VeYbt_Rkf4,roll,,,
fppenna,Félix Pedro Penna,Procurement data: where to find it and how to use it,"Do you wonder how much governments spend on public policies and what kind of goods and services they demand? Have you ever thought about who benefits the most from these contracts? Open contracting data can help answer these questions and provide valuable information for citizens and organizations worldwide. During this presentation, I will introduce the Open Contracting Partnership's Data Registry, one of the largest public contracting data repositories, offering hundreds of GB of standardized data in open formats. This data allows for monitoring public spending and searching for business opportunities, among other use cases. Join this session to discover how to take advantage of this powerful tool and learn the key steps to make the most of it.",Datos de contrataciones públicas: dónde encontrarlos y cómo utilizarlos,"¿Alguna vez te preguntaste cuánto dinero gastan los gobiernos para financiar sus políticas públicas y los bienes y servicios que contratan? ¿Sabés quiénes son las compañías que más se benefician de estos contratos? Los datos de contratación pública pueden ayudar a responder estas preguntas y proveer de información valiosa a ciudadanos y organizaciones de todo el mundo. En esta sesión, presentaré el Registro de Datos de Open Contracting Partnership, uno de los repositorios de datos de contrataciones públicas más grandes, que ofrece cientos de GB de información estandarizada y en formato abierto. Estos datos permiten el monitoreo del gasto y los contratos públicos, la búsqueda de oportunidades de negocio, entre otros casos de uso. Esta sesión ayudará a descubrir cómo hacer uso de la herramienta y cómo sacar provecho de sus datos.",https://drive.google.com/file/d/1omeVgUmuE53CZm3iLWS6HTmj-FmWQevf/view?usp=share_link,fppenna,fppenna,,
faruiz,Fernanda Aguirre Ruiz,Organize your data analysis; use a project template,"Every time we start a data-driven project, we invest part of our time creating and configuring that new project. However, with the help of Cookiecutter it is enough to execute a command to have the whole procedure solved by means of a project template.  When we work with data, we handle different versions of our databases, graphics and code files. This can result in disorganized and difficult to access projects, so when we use project templates we can automate this repetitive work by creating files and folders structured in a certain way to help us easily locate the different sections and standardize our projects. At the same time we can also automate more complex proceedings that we have incorporated in our workflows, such as installing certain libraries, starting git repositories, creating virtual environments, among many other possibilities.  ",Organiza tu análisis de datos; utiliza una plantilla de proyecto.,"Cada vez que iniciamos un proyecto basado en datos, invertimos parte de nuestro tiempo en crear y configurar ese proyecto nuevo. Sin embargo, con ayuda de Cookiecutter basta con ejecutar un comando para tener todo el procedimiento resuelto mediante una plantilla de proyecto. Cuando trabajamos con datos, manejamos diferentes versiones de nuestras bases de datos, gráficos y archivos con código. Esto puede dar lugar a proyectos desorganizados y de difícil acceso, por lo que cuando utilizamos plantillas de proyectos podemos automatizar este trabajo repetitivo creando archivos y carpetas estructurados de una manera determinada que nos ayuden a localizar fácilmente las diferentes secciones y a estandarizar nuestros proyectos. Al mismo tiempo también podemos automatizar procedimientos más complejos que hayamos incorporado a nuestros flujos de trabajo, tales como instalar ciertas librerías, iniciar repositorios de git, crear entornos virtuales, entre muchas otras posibilidades.",https://drive.google.com/file/d/17q9lyLSZtSSzygGoBsRJvJABxx7_sOwr/view?usp=sharing,fer-aguirre,feragru,,
fcampagnucci,Fernanda Campagnucci,Querido Diário': how an open source project is freeing official municipal records for 45 million people in Brasil (and counting!),"There are 5,570 cities and 26 states with the autonomy to design and implement policies in Brazil. Since there is no centralized place to look for the decision-making acts of these entities, the only reliable source of information is the official gazettes (or records), published in a closed and unstructured way in PDF files. The manual work of analyzing this mass of information is virtually impossible. To fill this data void, ​​we created an infrastructure capable of collecting, processing, and openly making this information available. The ""Querido Diario"" (""Dear Diary"" – a witty wordplay in reference to the official gazettes in Portuguese) MVP was launched more than a year ago and has been scaled and improved since then. With the help of a vibrant community, it has collected the entire time series of official diaries, creating a repository of more than 144,000 files, and started collecting them daily.",Querido Diário': cómo un proyecto de código abierto está liberando registros municipales oficiales para 45 millones de personas en Brasil (¡y contando!),"Hay 5.570 ciudades y 26 estados con autonomía para diseñar e implementar políticas en Brasil. Una vez que no existe un lugar centralizado para buscar los actos decisorios de estas entidades, la única fuente confiable de información son los diarios (o boletines/registros) oficiales, publicados de manera cerrada y no estructurada en archivos PDF. El trabajo manual de analizar esta masa de información es virtualmente imposible. Para llenar este ‘vacío de datos’, creamos una infraestructura capaz de recopilar, procesar y poner abiertamente a disposición esta información. El MVP de ""Querido Diario"" (queridodiario.ok.org.br) se lanzó hace más de un año y ha sido escalado y mejorado desde entonces. Con la ayuda de una comunidad vibrante, recopiló toda la serie temporal de los diarios oficiales, creó un depósito de más de 144 mil archivos y comenzó a recopilarlos automática y diariamente.",https://drive.google.com/file/d/1Ip1fmhd0ogDIM2Vj3DpzUQxgbQQiErkz/view?usp=share_link,campagnucci,fecampa,,
gmejias,Gabriela Mejias,Open research needs open (meta)data,"Metadata plays a key role in the scientific publication and dissemination process. It is only through metadata and identifiers  that each contribution, from research data to  article publication and beyond, becomes findable, accessible, interoperable and reusable. Persistent identifiers (PIDs) and their metadata are the backbone of scholarly communications, since only through them can the promise of sustainable access to research information be realized.  This presentation will highlight the importance of open metadata in scholarly communications to recognize a wide range of contributions to science and as a way to build trust in research.  We will also discuss the need for collaborative, community efforts to improve metadata creation and dissemination. Examples of organizations and researchers using open metadata will be presented.",La investigación abierta necesita (meta)datos abiertos,"Los metadatos desempeñan un papel fundamental en el proceso de publicación y difusión científica. Sólo a través de metadatos e identificadores es posible encontrar, acceder, interoperar y reutilizar cada contribución, desde los datos de investigación hasta la publicación del artículo y más allá. Los identificadores persistentes (PIDs) y sus metadatos son los pilares de las comunicaciones académicas, ya que sólo a través de ellos es posible realizar la promesa de un acceso sostenible a la información de la investigación. Esta presentación destacará la importancia de los metadatos abiertos en las comunicaciones académicas para reconocer una amplia gama de contribuciones a la ciencia y como forma de generar confianza en la investigación. También hablaremos de la necesidad de esfuerzos colaborativos y comunitarios para mejorar la creación y difusión de metadatos. Se presentarán ejemplos de organizaciones e investigadores que utilizan metadatos abiertos.",https://datacite.org/team.html,gmejias,gabioshka,,
grosati,Germán Rosati,Land use trajectories as text data,"How does land use change over time? Can agrarian frontier expansion and deforestation be detected in high resolution images over a long period of time? This question has implications in both environmental and socio-economic dimensions. Since the publication of large government databases derived from processed satellite images, new analytical and methodological approaches have emerged
Problems of this kind are usually addressed by aggregating information at higher levels (municipalities, departments, administrative areas). For this talk we propose another approach: to work at the pixel level. We will represent each land use pixel sequence over time as if it were a word. This makes it possible to use the so-called “edit distances” (which measure the number of operations necessary to transform one sequence into another) and to generate a matrix that allows clustering land use trajectories using simple techniques. 
We will present an illustration of this procedure covering the 1992-2020 period in Argentina (excluding Patagonia region), using information from the European Space Agency and Dynamic World. Our main goal is to obtain a map with the highest possible resolution that shows the following situations: 1) areas of recent expansion of the agrarian frontier; 2) areas of “consolidated” agriculture and 3) areas of recent urban expansion. We will present some cool visualizations of these trajectories and their spatial distributions.",Trayectorias de uso del suelo como datos de texto,"¿Cómo cambia el uso del suelo a lo largo del tiempo? ¿Pueden detectarse la expansión de la frontera agraria y la deforestación en imágenes de alta resolución durante un largo periodo de tiempo? Esta pregunta tiene implicaciones tanto en la dimensión medioambiental como en la socioeconómica. Desde la publicación de grandes bases de datos gubernamentales derivadas de imágenes de satélite procesadas, han surgido nuevos enfoques analíticos y metodológicos.
Los problemas de este tipo suelen abordarse agregando información a niveles superiores (municipios, departamentos, áreas administrativas). Para esta charla proponemos otro enfoque: trabajar a nivel de píxel. Representaremos cada secuencia de píxeles de uso del suelo a lo largo del tiempo como si fuera una palabra. Esto permite utilizar las llamadas ""distancias de edición"" (que miden el número de operaciones necesarias para transformar una secuencia en otra) y generar una matriz que permite agrupar las trayectorias de uso del suelo mediante técnicas sencillas. 
Presentaremos una ilustración de este procedimiento que cubre el período 1992-2020 en Argentina (excluyendo la región patagónica), utilizando información de la Agencia Espacial Europea y Dynamic World. Nuestro objetivo principal es obtener un mapa con la mayor resolución posible que muestre las siguientes situaciones 1) áreas de expansión reciente de la frontera agraria; 2) áreas de agricultura ""consolidada"" y 3) áreas de expansión urbana reciente. Presentaremos algunas visualizaciones interesantes de estas trayectorias y sus distribuciones espaciales.",http://investigadores.unsam.edu.ar/rest/img/fotos/Rosati-German-Federico.jpg,gefero,Crst_C,,
gsollazzo,Giuseppe Sollazzo,Keynote - Talking with data – stories and lessons from my data adventures,"Before his current role in the UK National Health Service as Deputy Director of the Artificial Intelligence Lab and Head of AI Skunkworks, Giuseppe's career journey included being a data wrangler, an open data activist, a computational research data support officer, and the Head of Data of a Government Department. This keynote will tell some stories from this 15-year long journey, and share the lessons Giuseppe has learned.",Hablar con los datos: historias y lecciones de mis aventuras con los datos,"Esta ponencia ofrecerá un relato desenfadado de algunas de las lecciones comunes aprendidas al ""hablar con datos"" como gestor de datos, activista y en el gobierno central.",,,,,
hdebat,Humberto Debat,Virus discovery at a global scale: a sustainable blueprint based on secondary analyses of open sequencing data,"Viruses are the most prevalent biological entities on earth. Notably, conservative estimates suggest that over 99.9% of the virosphere remains elusive. In this talk I will present novel strategies oriented to uncover the global viral dark matter based on secondary analyses of publicly available open sequencing data. Examples of robust detection and characterization of novel viruses with zoonotic competence with a focus in Latin America will be described. The potential impact in virus emergence and pandemic prediction will be discussed.",Descubrimiento de virus a escala mundial: un plan sostenible basado en análisis secundarios de datos de secuenciación abiertos,"Los virus son las entidades biológicas más prevalentes de la Tierra. Sin embargo, estimaciones conservadoras sugieren que más del 99,9% de la virosfera permanece oculta. En esta charla presentaré estrategias novedosas orientadas a descubrir la materia oscura viral global, basadas en análisis secundarios de datos de secuenciación abiertos y disponibles públicamente. Se describirán ejemplos de detección y caracterización sólidas de nuevos virus con competencia zoonótica, con especial atención en América Latina. Se discutirá el impacto potencial en la emergencia de virus y la predicción de pandemias.",https://drive.google.com/file/d/1Cbio70qgFuvvaojlaAbpT70FyCoU-CcO/view?usp=drivesdk,humbertodebat,humbertodebat,,
irpérez,Irene Ramos Pérez,Demonstrate to users and funding sources the public value of the Agrobiodiversity Information System in Mexico.,"We will present the strategies we have implemented to demonstrate to users and funding sources the public value of the Agrobiodiversity Information System (SIAgroBD) of the National Commission for the Knowledge and Use of Biodiversity (CONABIO). CONABIO is a government institution that compiles, analyzes and publishes data related to biodiversity and natural resources in Mexico. SIAgroBD is part of the GEF Mexican Agrobiodiversity Project, with FAO as the implementing agency. The objective of SIAgroBD is to generate, systematize and publish open data related to native crops of global relevance, including biological, geographic, agronomic, nutritional and cultural information. We will share the challenges we have faced in advocating for the development and maintenance of the SIAgroBD with different key stakeholders, such as funding sources and users, as well as strategies to address them. In particular, we highlight the need to build a common ground on the functionalities of an information system through capacity building; the incorporation of feedback processes with the user community, for example, through surveys or focus groups; and the design of narratives adapted to the expectations of different user profiles. These strategies have helped us to communicate the scope of the system, promote the adoption of our tools and, more broadly, show how the SIAgroBD can support decision making on conservation and food security issues. The lessons we have learned could be useful for other projects that need to demonstrate the public value of open data infrastructures in contexts where there are limited incentives for such developments.",Demostrar a personas usuarias y fuentes de financiamiento el valor público del Sistema de Información de Agrobiodiversidad en México,"Presentaremos las estrategias que hemos implementado para demostrar a personas usuarias y a fuentes de financiamiento el valor público del Sistema de Información de Agrobiodiversidad (SIAgroBD) de la Comisión Nacional para el Conocimiento y Uso de la Biodiversidad (CONABIO). CONABIO es una institución gubernamental que compila, analiza y publica datos relacionados con la biodiversidad y los recursos naturales en México. El SIAgroBD forma parte del Proyecto GEF de Agrobiodiversidad Mexicana, que tiene a la FAO como agencia implementadora. El objetivo del SIAgroBD es generar, sistematizar y publicar datos abiertos relacionados con cultivos nativos de relevancia global, incluyendo información biológica, geográfica, agronómica, nutricional y cultural. Compartiremos los retos que hemos enfrentado para abogar por el desarrollo y mantenimiento del SIAgroBD con diferentes actores clave, como fuentes de financiamiento y personas usuarias, así como las estrategias para atenderlos. En particular, destacamos la necesidad de construir un piso común sobre las funcionalidades de un sistema de información a través del desarrollo de capacidades; la incorporación de procesos de retroalimentación con la comunidad de usuarios, por ejemplo, mediante encuestas o grupos focales; y el diseño de narrativas adaptadas a las expectativas de diferentes perfiles de usuarios. Estas estrategias nos han ayudado a comunicar los alcances del sistema, a promover la adopción de nuestras herramientas y, de forma más amplia, mostrar cómo el SIAgroBD puede apoyar la toma de decisiones en temas de conservación y seguridad alimentaria. Las lecciones que hemos aprendido podrían ser útiles para otros proyectos que requieran demostrar el valor público de infraestructuras para datos abiertos, en contextos donde hay incentivos limitados para estos desarrollos.",https://drive.google.com/file/d/19exNgJXA-I9vZODrBtHKJmuTspxpxNpW/view?usp=share_link,iramosp,,,
ifeldfeber y yquirog,Ivana Feldfeber y Yasmín Quirog,Collecting data on gender-based violence in Latin American judiciaries,"In this talk we will present the joint work we are doing from DataGénero - Observatory of Data with a Gender Perspective and the Contraventional, Criminal and Misdemeanor Court No. 10 of the City of Buenos Aires, to build a tool (software) that generates structured data from unstructured data. Our software is called AymurAI, which in Quechua means harvest. We want to ""harvest"" data on judicial decisions on gender violence cases. Our tool uses rules and entity recognition (NER) to extract key information from court documents, goes through a validation screen and then structures the collected information into a gender-sensitive open dataset. Through this project we want to promote open justice, open government, open data with a gender perspective and the visibility of urgent problems through data.",Recolectando datos sobre violencias de género en los poderes judiciales latinoamericanos,"En esta charla presentaremos el trabajo en conjunto que estamos realizando desde DataGénero - Observatorio de Datos con Perspectiva de Género y el Juzgado N°10 Contravenciona, Penal y de Faltas de la Ciudad de Buenos Aires, para construir una herramienta (software) que genere datos estructurados a partir de datos no estructurados. Nuestro software se llama AymurAI que en quechua significa cosecha. Queremos ""cosechar"" datos sobre resoluciones judiciales sobre casos de violencia de género. Nuestra herramienta utiliza reglas y reconocimiento de entidades (NER) para extraer información clave de documentos judiciales, pasa por una pantalla de validación y luego estructura la información recolectada en un set de datos abiertos con perspectiva de género. A través de este proyecto queremos promover la justicia abierta, el gobierno abierto, los datos abiertos con perspectiva de género y la visibilización de problemáticas urgentes a través de los datos.",https://drive.google.com/file/d/1nIIDLYoYFepZ1rGWOZD_l239Yu_Dl9mB/view?usp=share_link,ivanafeldfeber,ivanafeld,,
jformoso y lascenzi y mrajngewerc y ploto,Jesica Formoso y Laurel Ascenzi y Mariela Rajngewerc y Patricia Loto,Communities of practice in Latin America and their influence on the dissemination of open science,"The open science movement has emerged in recent years mainly as a response to the replicability and reproducibility crises faced by different branches of science and seeks to ensure the transparency of research work by sharing the different stages of the workflow. More recently, different organizations have begun to promote these values through the development of public policies and the financing of projects. However, these measures vary greatly depending on the region. One possible tool for open science dissemination, potentially with more user acceptance, is communities of practice, self-organized and self-maintained groups of people who share a concern or passion for something they do and learn how to do it better as they interact regularly. A great growth of these communities has been observed in recent years in Latin America, many aimed at reducing the gender gap in STEAM such as R-Ladies, PyLadies, GeoChicas, TecnoLatinas and Women in Bioinformatics and Data Science Latin America, others focused on transmitting skills to teach computational tools such as The Carpentries or dedicated to teach open science tools and practices such as MetaDocencia. In this context, we ask ourselves what is the role of communities of practice in the dissemination and implementation of open science practices in general, and specifically, in the Latin American region. To this end, we conducted an exploratory analysis of the evolution of the use of the terms ""open science"" and ""open science"" over time from 2012 to the present. Where information was available, the representation of each region was studied. Finally, a social network analysis was performed to identify influential users and clusters of users and then the association of these with communities of practice was studied.",Comunidades de práctica en Latinoamérica y su influencia en la difusión de la ciencia abierta,"El movimiento de ciencia abierta emerge en los últimos años como respuesta principalmente a las crisis de replicabilidad y reproducibilidad por la que atraviesan distintas ramas de la ciencia y busca garantizar la transparencia de los trabajos de investigación compartiendo las distintas etapas del flujo de trabajo. Más recientemente, distintos organismos han comenzado a promover estos valores desde el desarrollo de políticas públicas y la financiación de proyectos Sin embargo, estas medidas varían mucho dependiendo de la región. Un instrumento posible para la difusión de la ciencia abierta, potencialmente con más aceptación de los usuarios, son las comunidades de práctica, grupos auto-organizados y auto-mantenidos de personas que comparten una preocupación o pasión por algo que hacen y aprenden a hacerlo mejor a medida que interactúan con regularidad. Se ha observado un gran crecimiento de estas comunidades en los últimos años en Latinoamérica, muchas dirigidas a reducir la brecha de género en STEAM como R-Ladies, PyLadies, GeoChicas, TecnoLatinas y Women in Bioinformatics and Data Science Latin America, otras enfocadas en transmitir habilidades para enseñar herramientas computacionales como The Carpentries o dedicadas a enseñar herramientas y prácticas de ciencia abierta como MetaDocencia. En este contexto, nos preguntamos cuál es el rol de las comunidades de práctica en la difusión e implementación de prácticas de ciencia abierta en general, y específicamente, en la región de Latinoamérica. Para ello, realizamos un análisis exploratorio de la evolución del uso de los términos “ciencia abierta” y “open science” con el tiempo de 2012 a la actualidad. Se estudió, en aquellos casos en que existía información al respecto, la representación de cada región. Finalmente, se realizó un análisis de redes sociales para identificar usuarios influyentes y agrupaciones de usuarios y luego se estudió la asociación de estos con comunidades de práctica.
Somos cuatro autoras: Jesica Formoso, Laurel Ascenzi, Patricia Loto y Mariela Rajngewerc",,MetaDocencia,metadocencia,,
jkerl,John Kerl,Miller: a swiss-army chainsaw for CSV and more,"Miller (`mlr`) is one of many command-line tools available for modern data processing. In this talk, we'll start from the basics of CSV manipulation: querying, sorting, converting to/from TSV and JSON, etc. We'll peek at some of the expressive things you can do using Miller's query language -- as well as some very simple and powerful things you can do without it. We'll see how Miller is useful for non-programmers as well as programmers: data analysts, system admins, researchers, etc. https://miller.readthedocs.io/en/latest/",Miller: una motosierra de ejército suizo para sus datos CSV y más,"Miller (`mlr`) es una de las muchas herramientas de línea de comandos disponibles para el procesamiento moderno de datos. En esta charla, empezaremos por los aspectos básicos de la manipulación de CSV: consulta, ordenación, conversión a/desde TSV y JSON, etc. Veremos algunas de las cosas más expresivas que se pueden hacer utilizando el lenguaje de consulta de Miller, así como algunas cosas muy sencillas y potentes que se pueden hacer sin él. Veremos cómo Miller es útil tanto para no programadores como para programadores: analistas de datos, administradores de sistemas, investigadores, etc. https://miller.readthedocs.io/en/latest/",https://johnkerl.org/pix/heads-icons-etc/jk-2020-09.jpg,johnkerl,hachyderm.iojohnkerl,,
jddsantos,Juan De Dios Santos,Baking bread on Sundays makes me happy,"I've been tracking my mood and activities for over 1000 days. What started as a time sink eventually became my daily meditation; my time to recap the day's moments, be genuine with myself, and ask, ""how am I feeling?"" This talk is a journey that explains how I felt during those 1000 days and how my daily activities influence my mood. This talk, which will be my most personal and intimate, will contain data visualizations, statistics, time series analysis, and fun anecdotes covering a range of emotions.",Hornear pan los domingos me hace feliz,"Llevo más de 1000 días registrando mi estado de ánimo y mis actividades. Lo que empezó como un sumidero de tiempo acabó convirtiéndose en mi meditación diaria; mi momento para pensar en los momentos del día, ser sincero conmigo mismo y preguntarme ""¿cómo me siento?"". Esta charla explica cómo me sentí durante esos 1000 días y cómo mis actividades diarias influyen en mi estado de ánimo. Esta charla, que será mi más personal e íntima, contendrá visualizaciones de datos, estadísticas, análisis de series temporales y divertidas anécdotas.",https://photos.app.goo.gl/S5e6q6tV8QdRQZc5A,juandes,jdiossantos,,
jprnicolini,Juan Pablo Ruiz Nicolini,Opening up the data and processes of public tourism statistics in Argentina,"The National Directorate of Markets and Statistics (DNMyE) of the Undersecretariat of Strategic Development of the National Ministry of Tourism and Sports (MTyD), is responsible for tourism statistics in the framework of Argentina's national statistical system. The presentation tells the experience of how we implement reproducible and open workflows in a team that produces, consolidates and analyses public statistics.",Abrir los datos y procesos de las estadísticas públicas de turismo en Argentina,"La Dirección Nacional de Mercados y Estadísticas (DNMyE) de la Subsecretaría de Desarrollo Estratégico del Ministerio de Turismo y Deportes de la Nación (MTyD), es la responsable de las estadísticas de turismo en el marco del sistema estadístico nacional de Argentina. La presentación cuenta la experiencia de cómo implementamos flujos de trabajo reproducibles y abiertos en un equipo que produce, consolida y analiza estadísticas públicas.",https://tuqmano.ar/images/logo.png,TuQmano,TuQmano,,
kljordan,"Kari L. Jordan, PhD","csv,conf Community Building with The Carpentries Toolkit of IDEAS","The Toolkit of IDEAS (Inclusion, Diversity, Equity and Accessibility Strategies) is a practical resource that connects teaching foundational coding and data science skills to principles of inclusion, diversity, equity, and accessibility. In this session, Kari L. Jordan (Executive Director for The Carpentries) introduces the csv,conf community to the toolkit and identifies approaches for applying it to various community contexts.","csv,conf Construcción de comunidad con The Carpentries Toolkit of IDEAS","El conjunto de herramientas de IDEAS (Estrategias de inclusión, diversidad, equidad y accesibilidad) es un recurso práctico que conecta la enseñanza de habilidades básicas de codificación y ciencia de datos con los principios de inclusión, diversidad, equidad y accesibilidad. En esta sesión, Kari L. Jordan (Directora Ejecutiva de The Carpentries) presenta a la comunidad csv,conf el conjunto de herramientas e identifica enfoques para aplicarlo a diversos contextos comunitarios.",https://drive.google.com/file/d/1406zezupHEiC-RZkpLJ5xGz2zetWDoz9/view?usp=sharing,kariljordan,drkariljordan,,
kram,Karthik Ram,Keynote,,Cómo cultivar un ecosistema de código abierto (OSE) sostenible,"Los investigadores crean una amplia gama de artefactos como software de código abierto, datos abiertos y hardware de código abierto como parte de sus esfuerzos de investigación. En casi todos los campos del quehacer científico, el software de código abierto ha transformado la forma en que generamos, adquirimos, procesamos, modelamos y extraemos conclusiones de los datos. La creciente disponibilidad de estas herramientas de código abierto ha contribuido a mejorar el rigor, la calidad y la reproducibilidad de la investigación. Garantizar que estos productos sigan siendo funcionales a lo largo del tiempo es un reto importante. Además, las organizaciones que mantienen estos productos de código abierto también necesitan sostenerse a sí mismas. En esta charla, exploro los diversos factores que son necesarios para transformar un esfuerzo en un ecosistema de código abierto (OSE) sostenible y exitoso.",,,,,
ksullivan ,Kathleen Sullivan ,Speed Bumps on the Road to Innovating with Government Open Data ,"Along with improving transparency and efficiency, open government data is supposed to support entrepreneurship, in the form of user-friendly apps and other business innovations. But the reality often falls short of the ideal. Developers who want to use government data run into poor data quality and documentation, insufficient off-the-shelf data products, limited options for automation and other stumbling blocks. The Washington state (US) open government data team will highlight common development barriers and ways to overcome them, using examples from state agencies’ efforts to open data on transit, internet access, legal cannabis, licensing and more.",Obstáculos en el camino hacia la innovación con datos públicos abiertos,"Además de mejorar la transparencia y la eficiencia, se supone que los datos públicos abiertos apoyan el espíritu emprendedor, en forma de aplicaciones fáciles de usar y otras innovaciones empresariales. Pero la realidad no suele estar a la altura del ideal. Los desarrolladores que quieren utilizar datos públicos se topan con una documentación y calidad de datos deficientes, productos de datos comerciales insuficientes, opciones limitadas de automatización y otros obstáculos. El equipo de datos gubernamentales abiertos del estado de Washington (EE.UU.) destacará las barreras de desarrollo más comunes y las formas de superarlas, utilizando ejemplos de los esfuerzos de las agencias estatales para abrir datos sobre el tránsito, el acceso a Internet, el cannabis legal, la concesión de licencias y más.",,,,,
khoeberling,Katie Hoeberling,The role of data in addressing environmental and climate injustice,"Around the world, communities organize to address environmental pollution and respond to climate change. Data can provide support, prompting us to frame questions from new perspectives, emphasizing place-based stories and experiences, and connecting the broad range of people and institutions responsible for environmental governance and stewardship. But the barriers to data uptake are enormous – data collected by regulatory agencies, researchers, or mandated industry requirements are decontextualized. They do not adequately reflect local values and cultural knowledge that may be critically important to policy or regulatory change. On the other hand, communities must navigate complex laws and policies within dense legal landscapes before effectively sharing their data and experiences. This talk will explore the conditions necessary for making environmental data usable beyond its original intent, strengthening multi-directional flows to tell new stories and build informed solutions that center communities bearing the brunt of pollution and climate change. It will do so by highlighting efforts which are attempting to integrate community data in research and government decisions, and to make regulatory data more accessible to researchers, journalists, community organizations, lawyers, and others. We’ll discuss mechanisms and strategies for shifting social, political, and technical systems toward creating environmental governance and stewardship processes that work across sectors. ",,,https://www.openenvironmentaldata.org/people/katie-hoeberling,khoeberling,shrubberling,,
kbadger,Kelsey Badger,Data Management on the Front Lines: Managing Administrative Data at the Source,"Over the past decade, it has become increasingly common that funders require researchers to submit a data management plan detailing how data produced during the project will be documented, secured, and shared. However, there is no equivalent requirement for managing government data that is “born-administrative”, even if it is commonly used downstream for research purposes. This has resulted in an uneven patchwork of government data management practices that greatly impact the accessibility and usability of administrative data for both its original purposes and in any subsequent re-use. This talk will explore this challenge through the example of child welfare electronic case records in the United States. This data is a particularly complex case study due to both its sensitivity and the distributed nature of the child welfare service system, which relies heavily on privatized contractors. This creates a correspondingly long tail of data management needs that are often not addressed by top-down data governance policies. How can data management practices be incorporated earlier in child welfare data collection without further burdening overworked frontline staff? Are there lessons to be learned from the last decade of teaching researchers how to better manage their data? And whose responsibility is all this anyway? ",Gestión de datos en primera línea: Gestión de datos administrativos en origen,"En la última década, cada vez es más habitual que las entidades financiadoras exijan a los investigadores que presenten un plan de gestión de datos en el que se detalle cómo se documentarán, protegerán y compartirán los datos producidos durante el proyecto. Sin embargo, no existe un requisito equivalente para la gestión de los datos gubernamentales ""de origen administrativo"", aunque se utilicen habitualmente con fines de investigación. Esto ha dado lugar a un mosaico desigual de prácticas de gestión de datos gubernamentales que repercute enormemente en la accesibilidad y usabilidad de los datos administrativos tanto para sus fines originales como en cualquier reutilización posterior. Esta charla explorará este reto a través del ejemplo de los registros electrónicos de casos de bienestar infantil en Estados Unidos. Estos datos constituyen un caso de estudio especialmente complejo debido tanto a su sensibilidad como a la naturaleza distribuida del sistema de servicios de bienestar infantil, que depende en gran medida de contratistas privatizados. Esto crea una larga cola de necesidades de gestión de datos que a menudo no se abordan en las políticas descendentes de gobernanza de datos. ¿Cómo pueden incorporarse antes las prácticas de gestión de datos en la recopilación de datos de bienestar infantil sin sobrecargar aún más al personal de primera línea? ¿Se pueden extraer lecciones de la última década de enseñanza a los investigadores sobre cómo gestionar mejor sus datos? ¿Y de quién es la responsabilidad de todo esto?",https://opic.osu.edu/badger.60?width=500&aspect=p,,,,
kmacpherson,Kevin MacPherson,The Jigsaw Puzzle of Cellular Identity,"Could you tell you were looking at a picture of the Mona Lisa if someone scratched off 99% of the image before handing it to you?
Scientists who try to explore how various cell types in the body maintain their specialized identities face a similar problem. Experiments that attempt to obtain the epigenetic profile of a cell barely scratch the surface of all the information encoded within it. In isolation, these results may be uninterpretable.
Returning to the Mona Lisa example, if you took your 1% remaining image and overlaid it on top of the actual Mona Lisa, you would know instantly what the original image was. My talk would discuss how this same thing applies to the field of epigenetics and how data curation of small files can help solve this problem.",El rompecabezas de la identidad celular,"¿Podría decir que está viendo un cuadro de la Mona Lisa si alguien rascara el 99% de la imagen antes de entregársela?
Los científicos que intentan explorar cómo los distintos tipos de células del cuerpo mantienen sus identidades especializadas se enfrentan a un problema similar. Los experimentos que intentan obtener el perfil epigenético de una célula apenas arañan la superficie de toda la información codificada en su interior. De forma aislada, estos resultados pueden ser ininteligibles.
Volviendo al ejemplo de la Mona Lisa, si se tomara el 1% de la imagen restante y se superpusiera sobre la Mona Lisa real, se sabría al instante cuál era la imagen original. En mi charla hablaré de cómo esto mismo se aplica al campo de la epigenética y de cómo la curación de datos de archivos pequeños puede ayudar a resolver este problema.",,,,,
lacion,Laura Acion,Keynote - Collective Creation of Open Science,"Communities of practice are key to develop and adopt Open Science, particularly in the Global South. In this talk, we will reflect on the value of developing connections to co-create work experiences and environments that increase the use of Open Science mostly in, but not limited to, Latin America. We will also consider recommendations based on our experiences to further build sustainable, local, and contextualized Open Science communities with a global connection. Most of the talk will be in English with captions in English throughout. ",Creación Colectiva de Ciencia Abierta,"Las comunidades de práctica son clave para desarrollar y adoptar la Ciencia Abierta, particularmente en el Sur Global. En esta charla, reflexionaremos sobre el valor de desarrollar conexiones para co-crear experiencias y ambientes de trabajo que incrementan el uso de Ciencia Abierta mayormente en, pero no limitados a, América Latina. También consideraremos recomendaciones basadas en nuestras experiencias para seguir construyendo comunidades de Ciencia Abierta sostenibles, locales, contextualizadas y globalmente conectadas. La mayor parte de la charla será en inglés con subtítulos en inglés en todo momento.",,,,,
laalemany,Laura Alonso Alemany,Bias auditing for all: moving into the territory,"Automated decision-making systems (automatic recommenders, credit risk classifiers, image recognition systems, translators, among others) involve increasingly important aspects of our lives, even affecting human rights. For this reason, auditing them becomes a necessity. However, systems involving artificial intelligence components are particularly difficult to audit, especially in cases where machine learning is applied, as they are often opaque and unintelligible to the person inspecting them. Many methods for auditing these systems have been proposed in academic circles, but most of the proposals involve technical complexities that exclude people with relevant experience for auditing, such as experience in discrimination or in the contexts of application of the technologies. In this talk we want to present a tool and a methodology to facilitate the involvement of experts, but without specific technical skills, in the audit of language technology biases. We will describe how we conceptualize inspection methods for these technologies by focusing on people with relevant experience, and making the technical complexities transparent. We will relate two practical experiences with people with expertise in very different types of biases and discriminations, which showed good feasibility of the tool. Finally, we will detail our future plans: to consolidate the tool as a software library, to compile, make available and make visible linguistic resources that allow systematizing the analysis of local biases, in collaboration with international teams with the same objectives, and finally to promote the adoption of the methodology associated with this tool in organizations and companies in our environment. A demo of the tool can be found at https://huggingface.co/vialibre.",Auditoría de sesgos para todos: avanzando en el territorio,"Los sistemas de toma de decisiones automatizados (recomendadores automáticos, clasificadores de riesgo crediticio, sistemas de reconocimiento de imágenes, traductores, entre otros) involucran aspectos cada vez más importantes de nuestras vidas, afectando incluso derechos humanos. Por esta razón, auditarlos se convierte en una necesidad. Sin embargo, los sistemas que involucran componentes de inteligencia artificial resultan especialmente difíciles de auditar, sobretodo en los casos en los que aplican aprendizaje automático, ya que suelen resultar opacos e ininteligibles para la persona que los inspecciona. Desde ámbitos académicos se han propuesto numerosos métodos para auditar estos sistemas, pero la mayor parte de propuestas involucran complejidades técnicas que excluyen a personas con experiencia relevante para la auditoría, como experiencia en discrimnación o en los contextos de aplicación de las tecnologías. En esta charla queremos presentar una herramienta y una metodología para facilitar el involucramiento de personas expertas, pero sin habilidades técnicas específicas, en la auditoría de sesgos de tecnologías del lenguaje. Describiremos cómo conceptualizamos los métodos de inspección de estas tecnologías poniendo el foco en las personas con experiencias relevantes, y haciendo transparentes las complejidades técnicas. Relataremos dos experiencias prácticas con personas expertas en muy diferentes tipos de sesgos y discriminaciones, que mostraron buena viabilidad de la herramienta. Finalmente, detallaremos nuestros planes a futuro: consolidar la herramienta como una librería de software, recopilar, disponibilizar y visibilizar recursos lingüísticos que permitan sistematizar el análisis de sesgos locales, en colaboración con equipos internacionales con los mismos objetivos, y finalmente impulsar la adopción de la metodología asociada a esta herramienta en organizaciones y empresas de nuestro entorno. Pueden encontrar una demo de la herramienta en https://huggingface.co/vialibre",https://www.famaf.unc.edu.ar/media/images/Alonso.e7111287.fill-1255x526.jpg,morlaicassiopea,morlaicassiopea,,
mtunga,Mahadia Tunga,Using Verbal Autopsy data to predict out-of-hospital causes of death,"Did you know that over 50% of people worldwide die outside health facilities? Thus, their cause of death is not known. Verbal autopsy(VA) is the survey-based method to determine symptoms or signs the deceased experienced before death. Using VA data and machine learning techniques, we can predict causes of death in areas where other forms of the autopsy are unavailable or not affordable such as in Low-income settings where more than 30% of people die outside health facilities. Having quality and adequate data on causes of death is important in understanding conditions of morbidity, which is an important aspect of quality healthcare interventions. I have developed a machine learning model to determine causes of death using bayesian networks.",Utilización de los datos de la autopsia verbal para predecir las causas de muerte extrahospitalaria,"¿Sabía que más del 50% de las personas de todo el mundo mueren fuera de los centros sanitarios? Por lo tanto, se desconoce la causa de su muerte. La autopsia verbal (VA) es el método basado en encuestas para determinar los síntomas o signos que el fallecido experimentó antes de morir. Con los datos de la autopsia verbal y las técnicas de aprendizaje automático, podemos predecir las causas de la muerte en zonas donde otras formas de autopsia no están disponibles o no son asequibles, como en los entornos de renta baja, donde más del 30% de las personas mueren fuera de los centros sanitarios. Disponer de datos adecuados y de calidad sobre las causas de muerte es importante para comprender las condiciones de morbilidad, un aspecto importante de las intervenciones sanitarias de calidad. He desarrollado un modelo de aprendizaje automático para determinar las causas de defunción mediante redes bayesianas.",https://theodi.org/person/mahadia-tunga/,,TungaMahadia,,
pbernaldo,Paz Bernaldo,Resources and challenges for building global equitable open science communities,"Data ethics, data sharing and analysis are key for any deep dive into open science. Open Life Science (OLS) is a community-oriented non-profit organization attempting such a dive: designed to provide structured training and mentoring to curious academics, researchers, undergraduates and people working on participatory projects. OLS provides expert consulting, resources and peer-based networks to build projects and become open science ambassadors. In this talk we present our fully online 16 weeks program, and reflect on the resources needed to train international members across time zones, working on diverse problems, with different levels of infrastructure and support. We then explore the challenges in forming equitable global communities, such as collaboration between high and low-resource settings, language and accessibility barriers, and our experience about where allocating funding and resources can make a difference.","Recursos y retos para crear comunidades científicas abiertas, equitativas y globales","La ética, el intercambio y el análisis de datos son fundamentales para cualquier inmersión en la ciencia abierta. Open Life Science (OLS) es una organización sin ánimo de lucro orientada a la comunidad que intenta realizar esa inmersión: está diseñada para ofrecer formación estructurada y tutoría a académicos, investigadores, estudiantes universitarios y personas curiosas que trabajan en proyectos participativos. OLS proporciona consultoría experta, recursos y redes de pares para construir proyectos y convertirse en embajadores de la ciencia abierta. En esta charla presentamos nuestro programa de 16 semanas totalmente en línea, y reflexionamos sobre los recursos necesarios para formar a miembros internacionales a través de zonas horarias, trabajando en diversos problemas, con diferentes niveles de infraestructura y apoyo. A continuación, exploramos los retos que plantea la formación de comunidades globales equitativas, como la colaboración entre entornos de altos y bajos recursos, las barreras lingüísticas y de accesibilidad, y nuestra experiencia sobre dónde la asignación de fondos y recursos puede marcar la diferencia.",,pazbc,pazbyc,,
pdatta,Polash Datta,Covid Deaths: What Happens When News is Transformed into Data,"In 2020, during the pick of Covid-19 infection a good number of people in Bangladesh died with Covid-19 symptoms most of who were not tested for Covid-19. Although these deaths were reported in media outlets, there was no such platform that could provide a comprehensive and comparative view on these deaths. Dataful developed an interactive visual on these deaths by collected reports from eight Bangladeshi media outlets and converting those into data. I want to talk about how did we collect, checked, and converted the news into data and develop the interactive data visual.",Muertes en Covid: Lo que ocurre cuando las noticias se transforman en datos,"En 2020, durante la recogida de la infección por Covid-19, un buen número de personas murieron en Bangladesh con síntomas de Covid-19, la mayoría de las cuales no se sometieron a la prueba de Covid-19. Aunque los medios de comunicación informaron de estas muertes, no existía ninguna plataforma que pudiera ofrecer una visión completa y comparativa de las mismas. Dataful desarrolló un visual interactivo sobre estas muertes recopilando informes de ocho medios de comunicación de Bangladesh y convirtiéndolos en datos. Quiero hablar de cómo recopilamos, comprobamos y convertimos las noticias en datos y desarrollamos el visual interactivo de datos.",,,polashdatta,,
rsefala,Raesetje Sefala,Constructing a Visual Dataset to Study the Effects of Spatial Apartheid in South Africa,"Over 27 years ago in South Africa, the Apartheid government forced non-European people to leave urban areas into neighborhoods like townships where they were marginalized in a controlled manner through laws and unfair budget constraints. In post-apartheid South Africa we still see no developments in townships and it is not easy to analyse what is happening in because in official government data like the census, the government lumps townships and suburbs together into a category known as formal residential neighborhoods. This masks the presence of townships, and prevents us from understanding whether or not they are changing after apartheid.  We created datasets that map all townships in South Africa together with these we use satellite imagery and machine learning techniques to analyse the evolution of neighborhoods post-apartheid. Even though apartheid has legally ended, photos show that townships are still very visibly different from suburbs. Our work segments out townships and analyses how they have changed over time, overlaying other datasets like government resource allocation data, there are disparities with urban areas. We give a few examples of what we’ve found, discuss our methodology, and talk about what we hope to do in the future.",Construcción de un conjunto de datos visuales para estudiar los efectos del apartheid espacial en Sudáfrica,"Hace más de 27 años, en Sudáfrica, el gobierno del apartheid obligó a los no europeos a abandonar las zonas urbanas para instalarse en barrios como los townships, donde fueron marginados de forma controlada mediante leyes y restricciones presupuestarias injustas. En la Sudáfrica posterior al apartheid, los townships siguen sin desarrollarse y no es fácil analizar lo que ocurre porque en los datos oficiales, como el censo, el gobierno agrupa los townships y los suburbios en una categoría conocida como barrios residenciales formales. Esto oculta la presencia de los townships y nos impide comprender si están cambiando o no después del apartheid. Hemos creado conjuntos de datos que cartografían todos los municipios de Sudáfrica y, con ellos, utilizamos imágenes por satélite y técnicas de aprendizaje automático para analizar la evolución de los barrios tras el apartheid. Aunque el apartheid haya terminado legalmente, las fotos muestran que los townships siguen siendo muy visiblemente diferentes de los suburbios. Nuestro trabajo segmenta los townships y analiza cómo han cambiado a lo largo del tiempo, superponiendo otros conjuntos de datos, como los datos de asignación de recursos gubernamentales, hay disparidades con las zonas urbanas. Damos algunos ejemplos de lo que hemos descubierto, comentamos nuestra metodología y hablamos de lo que esperamos hacer en el futuro.",https://media-exp1.licdn.com/dms/image/C5603AQF2sPdLw5aoAw/profile-displayphoto-shrink_800_800/0/1648848820091?e=2147483647&v=beta&t=HC4D2G-Acw6XirVtdY0dB-LwrBAOc1RNj1n_ZLJ4vk4,sefalab,bonjora,,
rsinclair,Rajiv Sinclair and Ayyub Ibrahim,​​Investigating police misconduct and migratory patterns,"​After gathering public records from hundreds of police departments and consolidating them into a single unified data structure, we were able to track individual police officers who move from one city to another after being accused of serious misconduct. 
​​In the course of investigating this and other systemic failures of the accountability system, we built a public database ( http://LLEAD.co ) and we cultivated a network of real-world practitioners who can put this tool to work on a day-to-day basis by using it to: defend individual members of the public against wrongful convictions ( https://ip-no.org ) , illustrate the mechanics of police impunity ( https://copwatchnola.wordpress.com ) , and advocate for meaningful changes on the policy level and beyond. 
​​In this talk, we will share techniques that we’ve developed for assembling individual profiles from a dynamic system made up of many messy data sources without any single unique identifier and we will discuss the challenges/opportunities for using data as a tool to transfer power to the public.",Investigación de la mala conducta policial y las pautas migratorias,"Tras recopilar registros públicos de cientos de departamentos de policía y consolidarlos en una única estructura de datos unificada, pudimos realizar un seguimiento de los agentes de policía que se trasladan de una ciudad a otra tras ser acusados de faltas graves de conducta. 
En el curso de la investigación de este y otros fallos sistémicos del sistema de rendición de cuentas, hemos construido una base de datos pública ( http://LLEAD.co ) y hemos cultivado una red de profesionales del mundo real que pueden poner esta herramienta a trabajar en el día a día mediante su uso para: defender a los miembros individuales del público contra condenas injustas ( https://ip-no.org ) , ilustrar la mecánica de la impunidad policial ( https://copwatchnola.wordpress.com ) , y abogar por cambios significativos a nivel político y más allá. 
En esta charla, compartiremos las técnicas que hemos desarrollado para reunir perfiles individuales a partir de un sistema dinámico compuesto por muchas fuentes de datos desordenados sin ningún identificador único y discutiremos los retos/oportunidades de utilizar los datos como una herramienta para transferir poder al público.",https://www.dropbox.com/s/idlwtpci488tebd/PDWblock.png?dl=1,ipno-llead,jeeves,,
rbiggs,Russ Biggs,OpenAQ: Wrangling the world's air quality data,"According to the World Health Organization, air pollution is estimated to cause 7 million premature deaths every year and 99% of the world’s population breathes unhealthy, polluted air. To begin to address the health effects of air pollution, air quality monitoring and data are essential to understanding health risk. Unfortunately, global monitoring data is siloed, disparate in format and accessibility. To address this challenge in data access, OpenAQ has developed the world’s largest open source and free data platform for air quality data. OpenAQ ingests millions of measurements a day across dozens of disparate sources and data formats to create a harmonized data repository of the world’s air quality data. This talk will explore how OpenAQ manages and wrangles data across the world’s air quality data sources. We will explore the wide range of data sources and formats and the challenges that arise when trying to harmonize data at a global scale.",OpenAQ: la gestión de los datos mundiales sobre calidad del aire,"Según la Organización Mundial de la Salud, se calcula que la contaminación atmosférica causa 7 millones de muertes prematuras al año y el 99% de la población mundial respira aire contaminado e insalubre. Para empezar a abordar los efectos de la contaminación atmosférica sobre la salud, la vigilancia y los datos sobre la calidad del aire son esenciales para comprender el riesgo para la salud. Desgraciadamente, los datos de vigilancia mundial están aislados y son dispares en cuanto a formato y accesibilidad. Para hacer frente a este problema de acceso a los datos, OpenAQ ha desarrollado la mayor plataforma gratuita y de código abierto del mundo para datos sobre la calidad del aire. OpenAQ ingiere millones de mediciones al día de docenas de fuentes y formatos de datos dispares para crear un repositorio de datos armonizado de los datos de calidad del aire del mundo. Esta charla explorará cómo OpenAQ gestiona y ordena los datos de las fuentes de datos de calidad del aire de todo el mundo. Exploraremos la amplia gama de fuentes y formatos de datos y los retos que surgen al intentar armonizar los datos a escala mundial.",https://russbiggs.com/img/russ.jpg,russbiggs,russ_biggs,,
sllópez,Sabrina Laura López,Towards a Community-Based Responsible Use of Health Data in Argentina and beyond,"Health data is, due to its sensitivity, internationally protected data. In this talk, we will share the experience of using health data for research in the Argentinian Public Health Research on Data Science and Artificial Intelligence for Epidemic Prevention (ARPHAI) project and the need to develop a Responsible Use of Data branch within ARPHAI. The objectives of this branch were initially focused on the project and rapidly reoriented towards raising awareness, problematizing, and mitigating the challenges related to the use of health data for the rest of the community at large. Some contributions of our work include developing an algorithm for de-identifying medical texts in Spanish, participating in the public consultation for updating Argentina’s Personal Data Law, and generating content to start addressing the challenges of using health data from different perspectives: patients, health professionals, data managers, and policymakers. We are working on further developing and sustaining a community of practice for the Responsible Use of Data in our region.",Hacia una comunidad sobre uso responsable de datos de salud en Argentina y más allá.,"Debido a su sensibilidad, los datos de salud son datos internacionalmente protegidos. En esta charla compartiremos nuestra experiencia usando datos de salud para investigación en el proyecto “Gestión epidemiológica basada en inteligencia artificial y ciencia de datos” (ARPHAI) y la necesidad de desarrollar el equipo de Uso Responsable de Datos. Los objetivos de este equipo fueron inicialmente concentrados al interior del proyecto y rápidamente se reorientaron hacia la concientización, problematización y mitigación de los desafíos relacionados al uso de datos de salud para el resto de la comunidad. Algunas de nuestras contribuciones incluyen el desarrollo de un algoritmo para desidentificar textos médicos en español, participar en la consulta pública para la actualización de la Ley de Datos Personales argentina y generar contenidos que comiencen a dar cuenta de los desafíos del uso de datos de salud desde diferentes perspectivas: pacientes, profesionales de la salud, gestores de datos y quienes diseñan políticas públicas. Estamos trabajando en desarrollar y sostener una comunidad de práctica para el Uso Responsable de Datos en nuestra región.",https://drive.google.com/file/d/1N7Ji2rZnhPLL2COOMSegTe1uXJhGeafi/view,SLLDeC,SLLDeC,,
scamargo y ynbsaibene,Sandro Camargo y Yanina Noemí Bellini Saibene,Tell me who you hang out with and I'll tell you who you are: a collaborative analysis using social network analysis.,"Communities of practice are spaces where people share knowledge and contribute to individual and group objectives.  Knowing the different types of community members, the different ways they can participate, what kind of collaborations exist, and among whom is an important input to understand the community and to be able to take actions to improve differents aspecto of the community, like members' engagement, reach a wider audience, and increase diversity, among other.

In this talk, we will present an analysis of rOpenSci networks since its inception to recognize types and themes of collaborations, actors in those collaborations, and sub-communities, among other aspects.

We will explain how we collect the information to feed the networks (e.g. blog post authoring, event organization, package authoring, package review, among others), how we process it, and what kind of community management actions we can take based on the results obtained.

All the source code and the data that can be public will be shared on a repository. ",Dime con quién andas y te diré quién eres: un análisis colaborativo mediante el análisis de redes sociales.,"Las comunidades de práctica son espacios donde las personas comparten conocimientos y contribuyen a objetivos individuales y de grupo. Conocer los diferentes tipos de miembros de la comunidad, las diferentes formas en que pueden participar, qué tipo de colaboraciones existen, y entre quiénes, es un insumo importante para entender la comunidad y poder tomar acciones para mejorar diferentes aspectos de la comunidad, como el compromiso de los miembros, llegar a una audiencia más amplia, y aumentar la diversidad, entre otros.

En esta charla, presentaremos un análisis de las redes de rOpenSci desde sus inicios para reconocer tipos y temas de colaboraciones, actores en esas colaboraciones y subcomunidades, entre otros aspectos.

Explicaremos cómo recopilamos la información para alimentar las redes (por ejemplo, autoría de entradas de blog, organización de eventos, autoría de paquetes, revisión de paquetes, entre otros), cómo la procesamos y qué tipo de acciones de gestión de la comunidad podemos tomar basándonos en los resultados obtenidos.

Todo el código fuente y los datos que puedan ser públicos se compartirán en un repositorio.",,,,,
scbaker ,Sarah Catherine Baker ,Solving Childhood Dementia: When data isn't enough ,"I work on a rare disease called Niemann Pick Disease Type C (NPC). NPC causes dementia, but rather than affecting elderly populations, NPC primarily affects children. Not only is NPC exceptionally rare, but individual patients often present very differently, making it hard to draw conclusions. My talk will be about the challenges of studying a disease when very little is know about it, and making the most of what little data you have. ",Resolver la demencia infantil: Cuando los datos no bastan,"Trabajo en una enfermedad rara llamada enfermedad de Niemann Pick tipo C (NPC). La NPC provoca demencia, pero en lugar de afectar a personas mayores, afecta sobre todo a niños. La NPC no sólo es excepcionalmente rara, sino que cada paciente suele presentar síntomas muy diferentes, lo que dificulta sacar conclusiones. Mi ponencia versará sobre los retos de estudiar una enfermedad de la que se sabe muy poco y sobre cómo aprovechar al máximo los pocos datos de que se dispone.",,,,,
tgovindasamy,Tricia Govindasamy,Building Digital Democracy Solutions in Kenya through Data,"In Kenya, it remains difficult for both watchdogs and citizens to understand how financial resources are utilised since it decentralised services from national to county-level governments in 2013. Code for Africa built a tool that holds the government accountable by liberating data, called PesaYetu. PesaYetu is an interactive website designed to easily identify and track promises made by county government officials and visualise budget data. With PesaYetu, you can explore, interpret and report on data-driven stories affecting local communities. The tool is aimed at storytellers to help empower citizens wanting to engage their leaders on issues concerning policy and governance at the county level.",Construir soluciones de democracia digital en Kenia a través de los datos,"En Kenia, sigue siendo difícil tanto para los organismos de control como para los ciudadanos comprender cómo se utilizan los recursos financieros desde que descentralizó los servicios del gobierno nacional a los gobiernos de condado en 2013. La Constitución de Kenia (2010) creó un sistema de gobierno descentralizado en el que el poder legislativo y ejecutivo se reparte entre el gobierno nacional y los 47 condados. La gestión de los recursos conlleva una mayor necesidad de rendición de cuentas pero, como en muchos otros países africanos, los datos del gobierno del condado son a menudo inaccesibles. Code for Africa ha creado una herramienta que obliga al Gobierno a rendir cuentas mediante la liberación de datos, llamada PesaYetu. PesaYetu es una palabra kiSwahili que se traduce como ""Nuestro dinero"". PesaYetu es un sitio web interactivo diseñado para identificar y rastrear fácilmente las promesas hechas por los funcionarios del gobierno del condado y visualizar datos presupuestarios. PesaYetu se creó para ayudar a impulsar la adopción de herramientas y técnicas de periodismo digital basadas en datos, y para mejorar el análisis local basado en pruebas y la información multimedia sobre cuestiones de desarrollo. El portal de datos PesaYetu se basa en la tecnología HURUmap de CfA, que ya se utiliza en las redacciones de cinco países y que ha demostrado su eficacia en los últimos años. en las redacciones de cinco países y que incorpora datos censales/demográficos detallados para ""poner a las para ""poner a la gente en los números"", de modo que los periodistas puedan inyectar más fácilmente en sus reportajes. Con PesaYetu, puedes explorar, interpretar e informar sobre historias basadas en datos que afectan a las comunidades locales. Utilizando los datos de PesaYetu, los periodistas capacitarán a sus comunidades para que se comprometan con sus líderes en cuestiones relativas a la política y la gobernanza a nivel de condado, lo que a su vez creará una ciudadanía informada y participativa en la que nadie se quede atrás en las áreas de desarrollo que sean de su interés. Entre las principales características del sitio se incluyen un mapa interactivo que muestra los condados cuyos datos están disponibles, un cuadro de búsqueda, así como documentos, datos y otros recursos. así como documentos, conjuntos de datos e historias basadas en datos publicadas por los socios. También hay una función de datos, que es un espacio para interactuar con diversos gráficos y datos visualizados. para seleccionar dos condados y comparar datos, gráficos descargables en varios formatos, una función para compartir y una función de ayuda para más información. Las visualizaciones de datos disponibles en PesaYetu son el resultado de más de un año de trabajo que ha consistido en liberar datos de largos informes en pdf. Los participantes podrán echar un vistazo a los numerosos procesos que se utilizaron durante las distintas fases del proyecto y los numerosos retos que se encontraron.",https://drive.google.com/file/d/1VsJWhwghh3ZkspTPVlXnFUtsxN25I4lv/view?usp=sharing,,triciagov,,
wasiqueira,William Antônio Siqueira,Agile Data Visualization with Dashbuilder,"Our local open data group (SJC digital) created data visualizations using Dashbuilder, a dashboard and data visualization tool. In this talk we would like to share how it is easy, no cost and fast to create consistent data visualizations using Dashbuilder. We will show examples of data visualizations created and made available in a few hours for different datasets including the so called ""Secret Budget"". Our vision is that Dashbuilder is a great tool for Open Data enthusiasts because its editor is available for any browser, it has no cost and run entirely on client!",Visualización rápida de datos con DashBuilder,"Nuestro grupo local de datos abiertos (SJC Digital) crea visualizaciones de datos utilizando DashBuilder, una herramienta de visualización de datos y creación de dashboards. En esta charla nos gustaría compartir como es fácil y rápido crear visualizaciones de datos consistentes utilizando DashBuilder. Mostraremos ejemplos de visualizaciones de datos creadas y puesto a disposicion en unas pocas horas para diferentes conjuntos de datos, incluido el controversial ""Presupuesto secreto"". Nuestra visión es que DashBuilder es una gran herramienta para los entusiastas de los datos abiertos porque su editor está disponible para cualquier navegador, ¡no tiene costo y se ejecuta por completo en el lado del cliente!",https://github.com/jesuino,jesuino,,,
,Malvika Sharan and Melissa Black ,Co-creating The Turing Way with global community,"The Turing Way - a community-led book for data science and research - originally emerged in response to the reproducibility crisis in science. Since 2019, the project has facilitated collaborations among an open, inclusive and collaborative community of researchers and organisations globally, enabling exchange of best practices in the guides for reproducibility, project design, collaboration, communication and ethics. The process of co-creation and the culture of collaboration is key to achieving The Turing Way’s mission to make data science accessible, comprehensible and beneficial for everyone.
Collaboration at a global scale with stakeholders with different needs inherently puts maintenance and questions of access at the forefront, rejecting the notion of 'moving fast and breaking things'. The Turing Way has therefore continued to evolve its approaches to collaboration, community engagement, sustainability, governance, and goals, all while ensuring that we embed EDIA (equity, diversity, inclusion and accessibility) at the core of all our efforts. This talk discusses The Turing Way - or more precisely ""Way(s)"" - that has emerged to impact the landscape and culture of data science, addressing questions around situated knowledge and globalisation, accessible open infrastructure, digital skills, data management frameworks, reproducible workflows, research infrastructure roles, team science and more. All information and discussions are managed via GitHub: https://github.com/alan-turing-institute/the-turing-way/.",Co-creando The Turing Way con la comunidad global,"The Turing Way, un libro dirigido por la comunidad para la ciencia y la investigación de datos, surgió originalmente en respuesta a la crisis de reproducibilidad en la ciencia. Desde el 2019, el proyecto ha facilitado colaboraciones entre una comunidad abierta, inclusiva y colaborativa de investigadores y organizaciones a nivel mundial, lo que permite el intercambio de mejores prácticas en las guías de reproducibilidad, diseño de proyectos, colaboración, comunicación y ética. El proceso de co-creación y la cultura de colaboración es clave para lograr la misión de The Turing Way: hacer que la ciencia de datos sea accesible, comprensible y beneficiosa para todos.
La colaboración a escala global con las partes interesadas, con diferentes necesidades inherentemente, pone el mantenimiento y las cuestiones de acceso en primer plano, rechazando la noción de 'moverse rápido y romper cosas'. Por lo tanto, The Turing Way ha seguido evolucionando sus enfoques de colaboración, participación comunitaria, sostenibilidad, gobernanza y objetivos, al tiempo que garantiza que integramos EDIA (equidad, diversidad, inclusión y accesibilidad) en el centro de todos nuestros esfuerzos. Esta charla analiza The Turing Way, o más precisamente ""Way(s)"" (caminos), que han surgido para impactar el panorama y la cultura de la ciencia de datos, abordando preguntas sobre conocimiento situado y globalización, infraestructura abierta accesible, habilidades digitales, marcos de gestión de datos, flujos de trabajo reproducibles, roles de infraestructura de investigación, ciencia de equipo y más. Toda la información y los debates se gestionan a través de GitHub: https://github.com/alan-turing-institute/the-turing-way/.",,malvikasharan,,,